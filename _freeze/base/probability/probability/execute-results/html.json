{
  "hash": "ddd9ca9f6b905d9a17574ed6c81c77d6",
  "result": {
    "markdown": "---\ntitle: Basic Probability\nformat: html\nreference-location: margin\nbibliography: ../../references.bib\nhtml-math-method: katex\neditor:\n  render-on-save: true\nexecute:\n  freeze: true\n---\n\n### Questions from @Bertsekas2000\n::: {.border} \n**Example 1.11**\nA class consisting of 4 graduate and 12 undergraduate students\nis randomly divided into 4 groups of 4. What is the probability that each group\nincludes a graduate student? We interpret randomly to mean that given the assignment of some students to certain slots, any of the remaining students is equally\nlikely to be assigned to any of the remaining slots. \n:::\n\n**Solution**:\n\nAt the beginning we have 16 different slots, where each group takes up 4 slots. Let $G$ be the event that every group has one grad student. \n$$\n\\begin{align}\nA_0 = \\text{\\{Grad student 1 is in different groups, but $P(A_0)=1$\\}}  \\nonumber \\\\\nA_1 = \\text{\\{Grad student 1 and 2 are in different groups\\}}  \\nonumber \\\\\nA_2 = \\text{\\{Grad student 1, 2 and 3 are in different groups\\}} \\nonumber \\\\\nA_3 = \\text{\\{Grad student 1, 2, 3, 4 are in different groups\\}} \\nonumber\n\\end{align}\n$$\n\nAfter grad student 1 has been picked only 15 people will be left, and since the available slots left is 3 we have 12 possible locations (3*4=12). Thus:\n\n\n$$\nP(A_1) = P(A_0 \\cap A_1)=P(A_0)P(A_1|A_0)=P(A_1|A_0)=12/15\n$$\n\nSimilarily:\n\n$$\nP(A_2) =P(A_1)P(A_2|A_1)=(12/15)*(2*4/14)=12*8/15*14\n$$\n$$\nP(A_3) = P(A_2)P(A_3|A_2)=P(A_2)*4/13=0.1406\n$$\n\nLet us see if this is really the case with a simulation\n\n::: {.cell execution_count=1}\n``` {.python .cell-code code-fold=\"true\"}\nimport numpy as np\nimport random\nfrom tqdm import tqdm\nvalid_array = []\nnum_sim = 1000 # NOTE : remember to set high for better results\n\nfor _ in range(num_sim):\n  student_id = np.arange(1, 17)\n\n  random.shuffle(student_id)\n\n  groups = [\n    student_id[0:4],\n    student_id[4:8],\n    student_id[8:12],\n    student_id[12:16],\n    ] \n\n  for g in groups:\n    num_grad_in_g = 0 \n    for g_id in [1,2,3,4]:\n      if g_id in g:\n        num_grad_in_g += 1\n    if num_grad_in_g > 1:\n      break\n    \n  if num_grad_in_g >1:\n    valid_array.append(0)\n  else: \n    valid_array.append(1)\n\nprint(f'Probability is {np.sum(valid_array)/float(num_sim)} after {num_sim} trials.')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nProbability is 0.118 after 1000 trials.\n```\n:::\n:::\n\n\n::: {.border} \n**Example 1.14.** Alice is taking a probability class and at the end of each week\nshe can be either up-to-date or she may have fallen behind. If she is up-to-date in\na given week, the probability that she will be up-to-date (or behind) in the next\nweek is 0.8 (or 0.2, respectively). If she is behind in a given week, the probability\nthat she will be up-to-date (or behind) in the next week is 0.6 (or 0.4, respectively).\nAlice is (by default) up-to-date when she starts the class. What is the probability\nthat she is up-to-date after three weeks?\n:::\n\n\n**Solution**\n\nLet $U_i$ be the event that Alice is up-to-date at the end of week $i$ and $\\overline{U}_i$ be not up-to-date, the goal is the find $P(U_3)$. \n\nStarting with \n$P(U_2)=P(U_2\\cap U_1)\\bigcup P(U_2\\cap\\overline{U}_1)$ which becomes $P(U_2) = P(U_1)P(U_2|U_1)+ P(\\overline{U}_1)P(U_2|\\overline{U}_1)$^[Additivity axiom: for disjoint sets $P(A_1 ∪ A_2 ∪···) = P(A_1) + P(A_2) + ···$]. Since she starts the week up-to-date, then $P(U_1)=0.8, P(\\overline{U}_1) = 0.2$.  \n\nThus, $P(U_2) = 0.8 * 0.8 + 0.2 * 0.4=0.72$. \nSimilarily: \n$$\nP(\\overline{U}_2) = P(U_1)P(\\overline{U}_2|U_1)+ P(\\overline{U}_1)P(\\overline{U}_2|\\overline{U}_1) \\\\\n=0.8 * 0.2 + 0.2 * 0.6 = 0.28\n$$\n\nFinally, \n\n$$\n\\begin{align}\nP(U_3) &= P(U_2)P(U_3|U_2)+ P(\\overline{U}_2)P(U_3|\\overline{U}_2) \\\\\n&=0.72*0.8 + 0.28 * 0.4 \\\\\n&=0.688\n\\end{align}\n$$\n\n\n\n::: {.border} \n**Example 1.17.** Consider an experiment involving two successive rolls of a 4-sided\ndie in which all 16 possible outcomes are equally likely and have probability 1/16.\n\n Are the events $A = \\text{\\{maximum of the two rolls is 2\\}}, B = \\text{\\{minimum of the two rolls is 2}\\}$ independent?\n::: \n\n**Solution** \n\nThey are not independent because $P(A) = 3/16, P(B) = 5/16, P(A\\cap B) = 1/16 \\neq 15/(16*16)$. ^[For independence, we need $P(A\\cap B) = P(A)P(B)$]\n\n\n::: {.border} \n**Example 1.22.** Network connectivity. A computer network connects two\nnodes A and B through intermediate nodes C, D, E, F.\nFor every pair of directly connected nodes, say i and j, there is a given probability\npij that the link from i to j is up. We assume that link failures are independent of each other. What is the probability that there is a path connecting A and B in\nwhich all links are up?\n\n![](images/Example1.22.jpg)\n::: \n**Solution** \n\n$$\n\\begin{align}\nP(l_1:= A\\rightarrow D \\rightarrow B) = 0.75 * 0.95 =0.7125\\\\\nP(l_2:=C\\rightarrow E \\rightarrow B) = 0.8 * 0.9 =0.72\\\\\nP(l_3:=C\\rightarrow F \\rightarrow B) = 0.95 * 0.85=0.8075 \\\\\n\\end{align} \n$$\n\nThe probability that $l_4 : C\\rightarrow B$ has at least one successful path is : \n\n$$P(l_2 \\cap l_3)\\cup P(l_2 \\cap \\overline{l_3}) \\cup P(\\overline{l_2} \\cap l_3) = 0.9461$$ \n\n$$P(l_5 : A\\rightarrow l_4) = 0.9 * 0.9461  = 0.85149 $$\nFinally,\n$$P(l_f) = P(l_1 \\cap l_5)\\cup P(l_1 \\cap \\overline{l_5}) \\cup P(\\overline{l_1} \\cap l_5) $$ \n$$P(l_f) = 0.7125 * 0.85149 + 0.7125 * (1- 0.85149) + (1-0.7125 ) * 0.85149=0.9573$$ \n\n::: {.border}\n**Example 2.1.** Let $Y = |X|$ and let us apply the preceding formula for the PMF\n$p_Y$ to the case where\n\n$$\np_X(x) = \n\\begin{cases}\n1/9, &\\text{if x is an integer in the range [−4, 4]} \\\\\n0,  &\\text{else}\n\\end{cases}\n$$\n\n\nThe possible values of $Y$ are $y = 0, 1, 2, 3, 4$.\n:::\n\n**Solution**\n$$\n\\begin{align}\np_Y(0)&= p_X(0) \\nonumber \\\\\np_Y(1)&= p_X(-1)  + p_X(1) \\nonumber \\\\\np_Y(2)&= p_X(-2)  + p_X(2) \\nonumber  \\\\\np_Y(3)&= p_X(-3)  + p_X(3)  \\nonumber \\\\\n\\end{align}\n$$\n\n\nThus the PMF of $Y$ is \n\n$$\np_Y(y) = \n\\begin{cases}\n1/9, &\\text{If $y=0$} \\\\\n2/9, &\\text{If $y=1,2,3,4$} \\\\\n0, &\\text{else} \\\\\n\\end{cases}\n$$\n\nThe mean^[$\\bold{E}[X]=\\sum_x x p_X (x)$] is then\n\n$$\n\\bold{E}[Y]=0 * 1/9 + 2/9 + 2*2/9 + 3*2/9 + 4*2/9=20/9\n$$\n\nThe variance^[$var(X) = \\bold{E}((X-\\bold{E}(X))^2)$], let $Z=(Y-\\bold{E}(Y))^2$\n$$\np_Z(z) = \n\\begin{cases}\n(20/9-1/9)^2, &\\text{If $y=0$} \\\\\n(20/9-2/9)^2, &\\text{If $y=1,2,3,4$} \\\\\n0, &\\text{else} \\\\\n\\end{cases}\n$$\n\nThus\n\n$$\nvar(Y) = (18/9)^2  +  2*(18/9)^2 +3*(18/9)^2 +4*(18/9)^2\n$$\n\n\n::: {.border}\n**Example 2.8.** Average Speed Versus Average Time. If the weather is good\n(which happens with probability 0.6), Alice walks the 2 miles to class at a speed of\nV = 5 miles per hour, and otherwise drives her motorcycle at a speed of V = 30\nmiles per hour. What is the mean of the time T to get to class?\n:::\n\n**Solution**\n$$\np_T(t) = \n\\begin{cases}\n0.6 & \\text{if $t = 2/5$} \\\\\n0.4 & \\text{if $t = 2/30$} \\\\\n\\end{cases}\n$$\n\nThus, \n\n$$\nE[T] = 0.6*2/5 + 0.4*2/30\n$$\n\nBut using $E[V]$ to find $E[T]$ using $E[T] = E[1/V] =1/E[V]$ doesn't work. Because $1/x$ is not linear.\n\n\n::: {.border}\n\n**Example 2.11.** Professor May B. Right often has her facts wrong, and answers\neach of her students’ questions incorrectly with probability 1/4, independently of\nother questions. In each lecture May is asked 0, 1, or 2 questions with equal probability 1/3. Let X and Y be the number of questions May is asked and the number of\nquestions she answers wrong in a given lecture, respectively. Construct the joint\nPMF $p_{X,Y} (x, y)$\n\n:::\n**Solution**\n\n\nThe PMF $p_{X,Y} (x, y)$^[Defined as $p_{X,Y} (x, y) = P(X=x, Y=y)$] can be found by using the multiplication rule^[$p_{X,Y}(x,y) = p_X(x)p_{Y|X}(y|x)$]:\n\n|     \t|     \t|      \t|      \t|\n|-----\t|-----\t|------\t|------\t|\n| y=2 \t| 0   \t| 0    \t| 1/48 \t|\n| y=1 \t| 0   \t| 1/12 \t| 6/48 \t|\n| y=0 \t| 1/3   \t| 3/12 \t| 9/48 \t|\n|     \t| x=0 \t| x=1  \t| x=2  \t|\n\n::: {.border}\n**Example 2.12.** Consider four independent rolls of a 6-sided die. Let $X$ be the\nnumber of 1’s and let $Y$ be the number of 2’s obtained. What is the joint PMF of\n$X$ and $Y$ ?\n:::\n\n**Solution**\n\nThe PMF of $X$ is:\n\n$$\np_X(x) =  \\dbinom{4}{x} \\left( \\frac{1}{6} \\right) ^x \\left( \\frac{5}{6}\\right) ^ {4-x}\n$$\n\n$Y$  is the number 2's, so conditioned on $x$  (the number of 1's), the possible choices is limited to $2,3,4,5,6$, and the number of 2's required becomes $4-x$\n$$\np_{Y|X}(y|x) =  \\dbinom{4-x}{y} \\left( \\frac{1}{5} \\right) ^y \\left( \\frac{4}{5}\\right) ^ {4-x-y}\n$$\n\nThus:\n\n$$\np_{X|Y}(x,y) = \n\\begin{cases}\n \\dbinom{4}{x} \\left( \\frac{1}{6} \\right) ^x \\left( \\frac{5}{6}\\right) ^ {4-x}  \\dbinom{4-x}{y} \\left( \\frac{1}{5} \\right) ^y \\left( \\frac{4}{5}\\right) ^ {4-x-y} &\\text{If $0\\leq x+y\\leq 4$} \\\\\n 0 &\\text{else}\n\\end{cases}\n$$\n\n::: {.border}\n**Example 2.15.** *Mean and Variance of the Geometric Random Variable.*\n\nYou write a software program over and over, and each time there is probability $p$\nthat it works correctly, independently from previous attempts. What is the mean\nand variance of $X$, the number of tries until the program works correctly?\n:::\n\n\n**Solution**\n\n$X$ is a geometric random variable with PMF:\n$$\np_X(k) = (1-p)^{k-1} p  \\quad k = 1,2,3,\\dots\n$$\n\nThe mean is \n$$\nE[X] = \\sum_{k=1}^{\\infty} k   (1-p)^{k-1} p\n$$\n\nThe variance is\n\n$$\n\\begin{align}\nvar(X) &= E[(X-E[X])^2] \\nonumber \\\\\n       &= \\sum_{k=1}^{\\infty} (k - E[X])   (1-p)^{k-1}  \\nonumber \\\\\n\\end{align}\n$$\n\nUsing the total expectation theroem^[The conditional expectation of $X$ given $y$ from $Y$ is $E[X|Y=y] = \\sum_x x p_{X|Y}(x | y)$. The **Total expectation theroem** is then $E[X] = \\sum_y p_Y(y) E[X|Y=y]$]. Let $A_1 = \\{\\text{first try is a success}\\}$, and $A_2 = \\{\\text{the first try is a failure}\\}$. \n\nThen $E[X| X=1] = \\sum_x x P(X = x | X=1) = \\sum_x x P(X = x \\cap X = 1)/P(X=1) = p/p + 0 + 0 + \\dots = 1$, since only the first value would contribute.\n\nSimilarily, \n\n$$\n\\begin{align}\nE[X| \\{X>1 \\}] &= \\sum_x x P(X=x \\cap X > 1)/P(X > 1)  \\\\\n&=  1 * P(X=1 \\cap X > 1)/P(X > 1) + \\\\ \n&\\sum_{x=2}^{\\inf} x P(X=x \\cap X > 1)/P(X > 1) \\\\\n&=(1-p)/(1-p) + \\\\\n&\\sum_{x=2}^{\\inf} x P(X=x) P(X > 1)/P(X > 1)   \\\\\n\\end{align} \n$$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n### Monte Hall simulation\n\n::: {.cell execution_count=2}\n``` {.python .cell-code code-fold=\"true\"}\nimport numpy as np\nimport random\nfrom tqdm import tqdm\n\ndef mt(switch):\n  win_array = []\n  for _ in range(num_sim):\n    # 1 - car\n    prizes = np.arange(1, 4)\n    random.shuffle(prizes)\n\n    pick_id = np.random.randint(0, 3)\n    car_id,  = np.where(prizes == 1) \n\n    allowed = [0,1,2]\n    allowed.remove(pick_id)\n    host_allowed = allowed.copy()\n\n    if prizes[pick_id] != 1:\n      host_allowed.remove(car_id[0])\n\n    allowed.remove(host_allowed[0])\n\n    if switch:\n      if prizes[allowed[0]] == 1: \n        win_array.append(1) \n      else:\n        win_array.append(0)\n    else:\n      if prizes[pick_id] == 1: \n        win_array.append(1) \n      else:\n        win_array.append(0)\n  return np.sum(win_array)/float(num_sim)\n\nprint(f'After {num_sim} games')\nprint(f'Probability of winning the car with switching is {mt(1)} ')\nprint(f'Probability of winning the car without switching is {mt(0)} ')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAfter 1000 games\nProbability of winning the car with switching is 0.695 \nProbability of winning the car without switching is 0.332 \n```\n:::\n:::\n\n\n",
    "supporting": [
      "probability_files"
    ],
    "filters": [],
    "includes": {}
  }
}