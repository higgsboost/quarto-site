---
title: NeRF with Jax 
format: html
reference-location: margin
jupyter: python3
bibliography: ../../references.bib
html-math-method: katex
editor:
  render-on-save: true
---

The NeRF paper [@Mildenhall2020], gives 



### Dataset
Get the tiny blender nerf dataset
<!-- ```{python}

#| code-fold: true
import os 
#if not os.path.exists('tiny_nerf_data.npz'):
#    !wget http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ECCV20/nerf/tiny_nerf_data.npz 
```
What does the data look like?
```{python}
import numpy as np
data = np.load('tiny_nerf_data.npz') # , allow_pickle=True)
images = data['images']
poses = data['poses']
focal = data['focal']

print(f'Images size : {images.shape}')
print(f'Pose : {poses[0]}')
print(f'Focal length: {focal}')
```

The pose includes the extrinsic parameters - rotation and translation matrices - $[R | T]$. And the focal length is the intrinsic property. Using this we can find the camera ray:

$$
\vec{r} = \vec{o} + t\vec{d}
$$ {#eq-camera-ray}

The vector $\vec{d}$, can be thought of as $\vec{d}= R\vec{d}_o$, where $\vec{d}_o$ is the direction vector of a standard pinhole camera without rotation - which can be found by using the focal length: $\vec{d}_o = f[x/f, y/f, -1]$


The cones in the below plot shows the direction of camera ray. The original is shown where $z=0$, and two additional poses are also plotted.
```{python}
#| code-fold: true
import plotly.graph_objects as go
#xv, yv = np.meshgrid(0, 500, indexing='xy')
H = 100
W = 100
x, y, z = np.mgrid[0:W:10, 0:H:10, 0:H:10]
x = x.flatten() - W/2
y = y.flatten() - H/2
z = z.flatten()*0

u = x/focal 
v = y/focal

w = -np.ones_like(x)
print(u[0], v[0], w[0])

fig = go.Figure()
fig.add_trace(go.Cone(
    x=x,
    y=y,
    z=z,
    u=u,
    v=v,
    w=w,
    ))

for i in range(0, 40,30):
    rot = poses[i][:3,:3]
    t = poses[i][:3,3]
    t= t[..., np.newaxis]
    p = np.stack([x, y, z]) 
    d = np.stack([u, v, w]) 
    p = rot @ p 
    d = rot @ d 
    nx, ny, nz = p 
    nu, nv, nw = d 
    fig.add_trace(go.Cone(
        x=nx,
        y=ny,
        z=nz,
        u=nu,
        v=nv,
        w=nw*2,
        ))

fig.show()

```
--->

```{python}
import jax
import jax.numpy as jnp

def get_ray(H, W, focal, pose):
    x, y = jnp.mgrid[0:W, 0:H]
    x = x - W/2
    y = y - H/2
    y = -y 

    x = x.flatten()
    y = y.flatten()

    direction = jnp.stack([x, y, -jnp.ones_like(x)])
    # Normalize direction
    direction_norm = jnp.linalg.norm(direction, ord=2, axis=0)
    direction = direction/direction_norm

    rot = pose[:3, :3] 
    direction = jnp.matmul(rot, direction)

    translation = pose[:3, 3]
    translation = translation[..., jnp.newaxis]
    origin = jnp.broadcast_to(translation, direction.shape)
    return origin, direction 

def get_ray_concrete(x):
    return get_ray(H, W, focal, x)

get_ray_batched = jax.vmap(get_ray_concrete, in_axes=(0))
``` 


### Camera ray and position encoding
Let's construct the function @eq-camera-ray.

```{python}
near = 2.
far = 6.
num_samples = 64

def r_func(o, d, t):
    r = o + t*d
    return r

t = jnp.linspace(near, far, num_samples)

get_ray_batched_jit = jax.jit(get_ray_batched)
origin, direction = get_ray_batched_jit(poses)
r = r_func(origin, direction, num_samples)
print(r.shape)
```

In **Section 5.1** the position encoding $\gamma$ is a mapping from $\mathbb{R}$ to $\mathbb{R}^{2L}$, where $L=10$ for the coordinate values $x$ and $l=4$ the direction vector :

$$
\gamma(p) = (sin(2^0\pi p), cos(2^0 p), \dots, sin(2^{L-1}\pi p), cos(2^{L-1} p))
$$


```{python}
def encoding_func(x, L):
    encoded_array = []
    for i in range(L):
        encoded_array.extend([jnp.sin(jnp.power(2, i) * jnp.pi * x), jnp.cos(jnp.power(2,i) * jnp.pi * x)])
    return jnp.array(encoded_array)

encoding_func_batched = jax.vmap(encoding_func, (0, None))
r_encoded = encoding_func_batched(r, 10)
print(f'Position before encoding shape {r.shape}')
print(f'Position after encoding shape {r_encoded.shape}')
```
### The render function

Equation (3) in the paper is:

$$
\hat{C} \vec(r) = \sum_{i=1}^{N} T_i (1- \text{exp}(-\sigma_i \delta_i))\vec{c}_i, \text{where}, T_i=\text{exp}\left( \sum_{j=1}^{i-1} \sigma_j \delta_j \right)
$$

## Hierarchical volume sampling

This method is used to sampling points closer to the surface of the objects. They first sample $N_c$ locations using stratified sampling, then they sample a second set $N_f$ using inverse transform sampling of the $\text{PDF}$ created using $w_i = T_i(1-\exp(-\sigma_i \delta_i))$, or

$$
f_X(x) = \frac{T_x(1-\exp(-\sigma_x \delta_x))}{k} \quad 1 < x < N_c 
$$


where $k=\sum_j^{N_c} w_j$ is the normalizing factor, this is the ensure that the area under the $\text{PDF}$ is 1. Let's plot the PDF for a ray (with 128 points) at the center of the image, and also verify that the area is 1 under the curve.

```{python}
#| code-fold: true
weights = np.squeeze(np.load('weights.npy'))

k = np.sum(weights) 
# normalize
weights = weights/k
dx = 1. 
x=np.arange(0, 128)

import plotly.express as px
fig = px.line(x=x, y=weights, \
    labels={
        'x': "counter along x",
        'y': "probability"
    }, title='PDF of weights')
fig.show()

# area
area = np.sum(weights * dx)
print(f'Area under the curve is :{area}')
```


### Inverse transform sampling

The idea behind inverse transform sampling is to use the inverse of the $\text{CDF}$ to generate random numbers for a probability distribution. The $\text{CDF}$ for a random variable $X$ is $F_X(x) = P(X\leq x)$. Then, generate random numbers from a uniform distribution  $Z \sim \text{uni}(0, 1)$, using this with the inverse $\text{CDF}$ (or  $F^{-1}_X(Z)$) to get samples from the original distribution.

Let's plot the cdf and the inverse cdf.
```{python}

cdf = np.cumsum(weights)
fig = px.line(x=x, y=cdf, title="CDF ", labels={
    'x': 'counter along x',
    'y': 'probability'
})
fig.show()

fig = px.line(x=cdf, y=x, title="Inverse CDF ", labels={
    'y': 'counter along x',
    'x': 'probability'
})
fig.show()



```

We can see that if we sample the inverse cdf - with a uniform distribution - the value of the y-axis (or the counter along the x-axis) would fall around 55, which corresponds to the section with the highest probability density of the pdf plot. 

Let's plot a histogram of the sampled counter using the above approach. 
```{python}
#| code-fold: true
Z = np.random.uniform(size=(1280))
def inverse_cdf(prob):
    return x[np.argmin(np.abs(prob-cdf))]

X = []

for z in Z:
    X.append(inverse_cdf(z))

    
fig = px.histogram(X) #, x="total_bill")
fig.show()
```